# Один День с Вышкой: Докеризаци

Этот репозиторий был создан для выполнения задания по курсу "Один день с Вышкой".

# Первое Задание

Послушайте немного теории про докер

# Второе Задание

Пишем вместе Dockerfile для бэкенда

```Dockerfile
FROM ghcr.io/astral-sh/uv:python3.13-alpine

ADD uv.lock pyproject.toml /app/
WORKDIR /app

RUN uv sync --frozen
ENV PATH="/app/.venv/bin:$PATH"

ADD . /app

EXPOSE 8000

ENTRYPOINT ["/bin/sh", "-c" , "fastapi run"]
```

Обьясню, что тут происходит:

- `FROM ghcr.io/astral-sh/uv:python3.13-alpine` - используем образ с uvicorn (типа pip, но лучше) и python 3.13 на базе alpine (это легкий дистрибутив линукса)

- `ADD uv.lock pyproject.toml /app/` - добавляем файлы с зависимостями в папку /app (Делаем это сначала, чтобы докер кэшировал слои и не пересоздавал их каждый раз, когда мы меняем код)

- `WORKDIR /app` - указываем, что все команды будут выполняться в папке /app
- `RUN uv sync --frozen` - устанавливаем зависимости из файла uv.lock (это аналог pip install -r requirements.txt)

- `ENV PATH="/app/.venv/bin:$PATH"` - добавляем папку с виртуальным окружением в переменную окружения PATH, чтобы можно было запускать команды из него
- `ADD . /app` - добавляем весь код в папку /app

- `EXPOSE 8000` - указываем, что приложение будет слушать на порту 8000
- `ENTRYPOINT ["/bin/sh", "-c" , "fastapi run"]` - указываем, что при запуске контейнера нужно выполнить команду fastapi run (это команда для запуска приложения на uvicorn)

# Третье Задание

Попробуйте написать такой же Dockerfile для фронтенда
Основные отличия:

- Используем `node:23-alpine`
- Вместо `uv.lock` и `pyproject.toml` копируем `package.json` и `package-lock.json`
- Вместо `uv sync --frozen` используем `yarn install --immutable`
- Приложение работает на порту `5173`
- Вместо `fastapi run` используем `yarn dev`

# Задание 4

Чтобы было легче запускать приложение добавляем файл `docker-compose.yml`

```yaml
services:
  db:
    image: postgres:alpine
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ci-example
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
  backend:
    build:
      context: ./backend
    environment:
      DB_URL: postgresql+psycopg://${DB_USER}:${DB_PASSWORD}@db:5432/ci-example
    ports:
      - "8000:8000"
    depends_on:
      - db
  frontend:
    build:
      context: ./frontend/
    ports:
      - "8080:8080"
    depends_on:
      - backend

volumes:
  db_data:
    driver: local
```

Что тут происходит:

- `services:` - Отвечает за контейнеры, которые мы будем запускать

- `db:` - Контейнер с базой данных

- `image` - Позволяет указать, какой образ использовать

- `environment` - Позволяет указать переменные окружения, которые будут доступны в контейнере (Здесь мы указываем пользователя, пароль и имя базы данных). Полезно гуглить, какие переменные мы можем передать в контейнер (можно быстрее добиться желаемого, а не писать свой Dockerfile). Значения, которые записаны так: `${}` переменных берутся из файла `.env`, который должен находиться в корне проекта.

- `ports` - Позволяет указать, какие порты нужно пробросить из контейнера на хост (сперва указыается порт на компе, потом на контейнере) можно пробросить несколько портов (на новой строчке указываем `- "порт:порт"`)

- `volumes` (который внутри сервиса) - Позволяет указать, какие папки нужно смонтировать из контейнера на комп (сперва указыается папка на компе, потом на контейнере). Это нужно, чтобы данные сохранялись, когда пересоздается контейнер (например, когда мы меняем код и пересоздаем контейнер). Если не указать, то данные будут храниться только в контейнере и при его удалении все данные пропадут. Можно указать несколько папок по такой же схеме.

- `depends_on` - Позволяет указать, какие контейнеры должны быть запущены перед этим контейнером (например, сначала запускаем базу данных, а потом бэкенд). Если не указать, то контейнеры могут запускаться в любом порядке и приложение может не работать. Можно указать несколько контейнеров.

- `build` - Позволяет указать, что нужно собрать образ из Dockerfile. Указываем путь к папке с Dockerfile через `context`.

- `volumes` (который глобальый) - Обьявляем места, где будут храниться данные для нашего приложения. В данном случае мы создаем папку `db_data`, которая будет хранить данные базы данных.

Запускаем приложение

```bash
docker-compose up -d
```

# Задание 5

Добавим GitHub Actions для автоматического запуска тестов
Так-же его можно исопльзовать для деплоя приложения на сервер (но мы этого скорее всего не успеем обсудить)

создаем файл `.github/workflows/run-backend-tests.yml`

```yaml
name: Run backend tests
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: install uv
        uses: astral-sh/setup-uv@v5
        with:
          version: "0.6.14"

      - name: install python
        working-directory: ./backend
        run: uv python install

      - name: install dependencies
        working-directory: ./backend
        run: uv sync --frozen

      - name: run tests
        working-directory: ./backend
        run: uv run pytest
```

Немного про стркутуру файла:

- `name` - Имя нашего workflow (можно любое)
- `on` - Когда запускать workflow (в данном случае при пуше в ветку main и при создании pull request в ветку main)
- `jobs` - Задачи, которые нужно выполнить (в данном случае только одна)
- `test` - Имя задачи (можно любое)
- `runs-on` - На какой системе запускать задачу (в данном случае на ubuntu)
- `steps` - Шаги, из которых состоит задача (они представляют собой готовые действия, сделанные другими людьми, которые мы можем использовать) их можно найти на сайте GitHub Actions

- `name` - Имя шага (можно любое)
- `uses` - наименование действия, которое мы хотим использовать
- `with` - Параметры, которые мы передаем в действие
- `run` - Если мы не используем готовое действие, то указываем команду, которую хотим выполнить
- `working-directory` - Папка, в которой нужно выполнить команду

Теперь, когда вы создали файл, закомиттье его, и посмотрите, что будет.
